{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-Categorization\n",
    "By Trang VO\n",
    "\n",
    "https://github.com/trang-h-vo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data &  libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T10:37:59.382716Z",
     "start_time": "2018-01-30T10:37:44.208164Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>create_time</th>\n",
       "      <th>article_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>provider</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>category_from_provider</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61322</th>\n",
       "      <td>2015-09-17 11:43:14</td>\n",
       "      <td>1023623</td>\n",
       "      <td>EDEM</td>\n",
       "      <td>Profhome</td>\n",
       "      <td>XXL Papier peint non-tissé en relief rayures d...</td>\n",
       "      <td>&lt;p&gt;Fabricant: EDEM, Collection: VERSAILLES&lt;br ...</td>\n",
       "      <td>23.95</td>\n",
       "      <td>None</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107983</th>\n",
       "      <td>2014-03-15 05:43:46</td>\n",
       "      <td>2974561</td>\n",
       "      <td>ELEM GARDEN TECHNIC</td>\n",
       "      <td>Toupour France</td>\n",
       "      <td>3 couteaux de peintre inox</td>\n",
       "      <td>&lt;p&gt;3 couteaux de peintre inox&lt;/p&gt;&lt;br /&gt;&lt;strong...</td>\n",
       "      <td>22.39</td>\n",
       "      <td>Racine &gt; Accueil &gt; Outillage manuel &gt; Le plaqu...</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103284</th>\n",
       "      <td>2016-11-16 03:43:21</td>\n",
       "      <td>2729208</td>\n",
       "      <td>EMINZA</td>\n",
       "      <td>Eminza</td>\n",
       "      <td>Paire de voilage (60 x H120 cm) Duo Blanc Azur</td>\n",
       "      <td>Paire de voilage (60 x H120 cm) Duo Blanc Azur...</td>\n",
       "      <td>6.90</td>\n",
       "      <td>Voilage</td>\n",
       "      <td>3165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                create_time  article_id                brand        provider  \\\n",
       "61322   2015-09-17 11:43:14     1023623                 EDEM        Profhome   \n",
       "107983  2014-03-15 05:43:46     2974561  ELEM GARDEN TECHNIC  Toupour France   \n",
       "103284  2016-11-16 03:43:21     2729208               EMINZA          Eminza   \n",
       "\n",
       "                                                    title  \\\n",
       "61322   XXL Papier peint non-tissé en relief rayures d...   \n",
       "107983                         3 couteaux de peintre inox   \n",
       "103284     Paire de voilage (60 x H120 cm) Duo Blanc Azur   \n",
       "\n",
       "                                              description  price  \\\n",
       "61322   <p>Fabricant: EDEM, Collection: VERSAILLES<br ...  23.95   \n",
       "107983  <p>3 couteaux de peintre inox</p><br /><strong...  22.39   \n",
       "103284  Paire de voilage (60 x H120 cm) Duo Blanc Azur...   6.90   \n",
       "\n",
       "                                   category_from_provider  category_id  \n",
       "61322                                                None          449  \n",
       "107983  Racine > Accueil > Outillage manuel > Le plaqu...          440  \n",
       "103284                                            Voilage         3165  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(str(os.getcwd()) + '/new_products_autocategorization.parquet')\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select 500 most popular categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2319</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>449</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>490</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3936</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1866</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1635</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>1104</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1239</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>1223</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>1103</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     category_id  counts\n",
       "0           2319     176\n",
       "1            449     148\n",
       "2            490     121\n",
       "3           3936     115\n",
       "4           1866     107\n",
       "..           ...     ...\n",
       "495         1635       5\n",
       "496         1104       5\n",
       "497         1239       5\n",
       "498         1223       5\n",
       "499         1103       5\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_categories = df['category_id'].value_counts().reset_index()[:500]\n",
    "top_categories.columns = ['category_id', 'counts']\n",
    "top_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataFrame with 500 most popular categories & use it for the new experiment\n",
    "df_new = df.loc[df['category_id'].isin(top_categories['category_id']), :]\n",
    "\n",
    "# fill in missing values\n",
    "df_new.fillna(' ', inplace=True)\n",
    "\n",
    "# set text data to lower strings\n",
    "for col in ['brand', 'provider', 'title', 'category_from_provider', 'description']:\n",
    "    df_new[col] = df_new[col].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train & validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features & target\n",
    "X = df_new.drop('category_id', axis=1)\n",
    "y = df_new['category_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (6642, 8)\n",
      "X_test shape: (738, 8)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,\n",
    "                                                                    stratify=y, random_state=1)\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Concatenate X_train & X_test to have similar feature engineering\n",
    "X_train['is_train'] = 1\n",
    "X_test['is_train'] = 0\n",
    "\n",
    "X_fe = pd.concat([X_train, X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fe['price_rounded'] = X_fe['price'].round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the text cols into 1 column to tokenize altogether\n",
    "X_fe['full_text'] = X_fe['title'] + ' ' + X_fe['category_from_provider'] + ' ' + X_fe['description']\\\n",
    "                    + ' ' + X_fe['brand'] + ' ' + X_fe['provider'] + ' ' + X_fe['price_rounded'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text preprocessor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries for text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install spacy-lefff\n",
    "# !python3 -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "from bs4 import BeautifulSoup # to remove htmml tags\n",
    "import fr_core_news_sm # lemmatization\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.fr import French\n",
    "from spacy_lefff import LefffLemmatizer, POSTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # alternative French stopwords list\n",
    "# from nltk.corpus import stopwords\n",
    "# stop_words = stopwords.words('french')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a French stop_words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop\n",
    "fr_stop_words = list(fr_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for French lemmatization\n",
    "nlp = fr_core_news_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessor(doc):\n",
    "    # remove html tags\n",
    "    doc = doc.replace('<', ' ').replace('>', ' ')\\\n",
    "                .replace('/', ' ').replace('(\\)', ' ')\\\n",
    "                .replace('.', ' ').replace(':', ' ')\\\n",
    "                .replace('!', ' ').replace('(', ' ')\\\n",
    "                .replace(')', ' ').replace(',', ' ')\n",
    "\n",
    "    words = doc.split()\n",
    "    doc_filtered = ''\n",
    "    \n",
    "    for w in words: \n",
    "        if (len(w)>=3) and (w not in fr_stop_words): \n",
    "            doc_filtered = doc_filtered + w + ' '\n",
    "            \n",
    "    tokens = nlp(doc_filtered)\n",
    "    lemmas = '' \n",
    "    \n",
    "    for tok in tokens:  \n",
    "         # only keep nouns, verbs, adjectives & numbers\n",
    "        if tok.pos_ in ('ADP', 'ADV', 'DET', 'PRON', 'PROPN', 'PUNCT'):\n",
    "            pass\n",
    "        elif (tok.pos_ in ('NOUN', 'ADJ', 'VERB')):\n",
    "            # lemmatize\n",
    "            lemmas = lemmas + tok.lemma_ + \" \"\n",
    "        else:\n",
    "            lemmas = lemmas + str(tok) + \" \"\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fe['full_text_preprocessed'] = X_fe['full_text'].apply(text_preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-Idf & SGDClassifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(binary=True, max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7380, 10000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_text_vectorized = vectorizer.fit_transform(X_fe['full_text_preprocessed'])\n",
    "full_text_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec = full_text_vectorized.tocsr()[:6642,:]\n",
    "X_test_vec = full_text_vectorized.tocsr()[6642:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score, RepeatedKFold, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Classifier CV scores on full train set:\n",
      " [0.73137698 0.71181339 0.74021084 0.7371988  0.75903614 0.74191121\n",
      " 0.73739654 0.74698795 0.7311747  0.72966867]\n",
      "CV mean score:  0.7366775227320115\n",
      "CV scores std:  0.011715815069054898\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier(max_iter=20000, alpha=0.0001, n_jobs=-1, random_state=123)\n",
    "cv = cross_val_score(sgd, X_train_vec, y_train, scoring='accuracy',\n",
    "                     cv=RepeatedKFold(n_splits=5, n_repeats=2))\n",
    "print('SGD Classifier CV scores on full train set:\\n', cv)\n",
    "print('CV mean score: ', cv.mean())\n",
    "print('CV scores std: ', cv.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get scores on the full train set using cross_val_predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Classifier scores on full train set:\n",
      "Accuracy score:  0.7621198434206564\n",
      "F1 macro score:  0.6568292204998418\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_sgd = cross_val_predict(sgd, X_train_vec, y_train, cv=5, n_jobs=-1)\n",
    "print('SGD Classifier scores on full train set:')\n",
    "print('Accuracy score: ', accuracy_score(y_train, y_train_pred_sgd))\n",
    "print('F1 macro score: ', f1_score(y_train, y_train_pred_sgd, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get score on the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD scores on validation set:\n",
      "Accuracy score:  0.7560975609756098\n",
      "F1 macro score:  0.6302208624586539\n"
     ]
    }
   ],
   "source": [
    "sgd.fit(X_train_vec, y_train)\n",
    "y_pred_sgd = sgd.predict(X_test_vec)\n",
    "print('SGD scores on validation set:')\n",
    "print('Accuracy score: ', accuracy_score(y_test, y_pred_sgd))\n",
    "print('F1 macro score: ', f1_score(y_test, y_pred_sgd, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD performs quite well and has no overfitting issue, given the small training set and high number of target classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks with TensorFlow/Keras\n",
    "As the training set is rather small compared to the number of classes, I'll use MLP with 1 hidden layer. Other tests show that with more hidden layers, the models perform poorly.\n",
    "\n",
    "Steps inlude:\n",
    "\n",
    "- Use `Keras Tokenizer` to transform the text to sequences and then to matrices\n",
    "- Transform the target labels before feeding to MLP\n",
    "- Test a simple model\n",
    "- Tune hyperparameters using Keras Tuners: `RandomSearch` & `Hyperband Tuner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(f'TensorFlow version: {tf.__version__}')\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import callbacks\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform text to sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000\n",
    "num_tokenizer = Tokenizer(num_words=max_words)\n",
    "\n",
    "# fit on preprocessed text\n",
    "num_tokenizer.fit_on_texts(X_fe['full_text_preprocessed'])\n",
    "X_full_sequences = num_tokenizer.texts_to_sequences(X_fe['full_text_preprocessed'])\n",
    "\n",
    "X_train_sequences = X_full_sequences[:6642]\n",
    "X_test_sequences = X_full_sequences[6642:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the sequences to matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing sequence data...\n",
      "X_train_keras shape: (6642, 10000)\n",
      "X_test_keras shape: (738, 10000)\n"
     ]
    }
   ],
   "source": [
    "print('Vectorizing sequence data...')\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "\n",
    "X_train_keras = tokenizer.sequences_to_matrix(X_train_sequences, mode='binary')\n",
    "X_test_keras = tokenizer.sequences_to_matrix(X_test_sequences, mode='binary')\n",
    "\n",
    "print('X_train_keras shape:', X_train_keras.shape)\n",
    "print('X_test_keras shape:', X_test_keras.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform the target variable for keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concaternate y_train & y_test for transformation\n",
    "y_full = pd.concat([y_train, y_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert class vector to binary class matrix (for use with categorical_crossentropy)\n",
      "y_train_keras shape as a binary class matrix: (6642, 500)\n",
      "y_test_keras shape as a binary class matrix: (738, 500)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical \n",
    "print('Convert class vector to binary class matrix (for use with categorical_crossentropy)')\n",
    "nb_classes = y_full.unique().shape[0]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_full)\n",
    "y_train_encoded = encoder.transform(y_train)\n",
    "y_test_encoded = encoder.transform(y_test)\n",
    "\n",
    "y_train_keras = to_categorical(y_train_encoded, nb_classes)\n",
    "y_test_keras = to_categorical(y_test_encoded, nb_classes)\n",
    "print('y_train_keras shape as a binary class matrix:', y_train_keras.shape)\n",
    "print('y_test_keras shape as a binary class matrix:', y_test_keras.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "997/997 [==============================] - 7s 5ms/step - loss: 5.5999 - accuracy: 0.1620 - val_loss: 4.0524 - val_accuracy: 0.3188\n",
      "Epoch 2/10\n",
      "997/997 [==============================] - 4s 4ms/step - loss: 3.3339 - accuracy: 0.4340 - val_loss: 3.0665 - val_accuracy: 0.4556\n",
      "Epoch 3/10\n",
      "997/997 [==============================] - 4s 4ms/step - loss: 2.2759 - accuracy: 0.6090 - val_loss: 2.4747 - val_accuracy: 0.5444\n",
      "Epoch 4/10\n",
      "997/997 [==============================] - 4s 4ms/step - loss: 1.5575 - accuracy: 0.7499 - val_loss: 2.0972 - val_accuracy: 0.5970\n",
      "Epoch 5/10\n",
      "997/997 [==============================] - 4s 4ms/step - loss: 1.1101 - accuracy: 0.8344 - val_loss: 1.8334 - val_accuracy: 0.6481\n",
      "Epoch 6/10\n",
      "997/997 [==============================] - 4s 4ms/step - loss: 0.7448 - accuracy: 0.9068 - val_loss: 1.6529 - val_accuracy: 0.6707\n",
      "Epoch 7/10\n",
      "997/997 [==============================] - 4s 4ms/step - loss: 0.5091 - accuracy: 0.9451 - val_loss: 1.5117 - val_accuracy: 0.6797\n",
      "Epoch 8/10\n",
      "997/997 [==============================] - 4s 4ms/step - loss: 0.3327 - accuracy: 0.9689 - val_loss: 1.4175 - val_accuracy: 0.6767\n",
      "Epoch 9/10\n",
      "997/997 [==============================] - 4s 4ms/step - loss: 0.2318 - accuracy: 0.9848 - val_loss: 1.3602 - val_accuracy: 0.6857\n",
      "Epoch 10/10\n",
      "997/997 [==============================] - 4s 4ms/step - loss: 0.1545 - accuracy: 0.9895 - val_loss: 1.3123 - val_accuracy: 0.6887\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 10\n",
    "\n",
    "nn1 = Sequential()\n",
    "nn1.add(Dense(30, input_shape=(max_words,)))\n",
    "nn1.add(Activation('tanh'))\n",
    "# nn1.add(Dropout(0.4))\n",
    "\n",
    "nn1.add(Dense(nb_classes))\n",
    "nn1.add(Activation('softmax'))\n",
    "\n",
    "nn1.compile(loss='categorical_crossentropy',\n",
    "          optimizer='adam',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "history_1 = nn1.fit(X_train_keras, y_train_keras, epochs=nb_epoch, validation_split=0.1, batch_size=6, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pd.DataFrame(history_1.history).plot(figsize=(6,4)) #, marker='o'\n",
    "# plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 6ms/step - loss: 1.3606 - accuracy: 0.6829\n"
     ]
    }
   ],
   "source": [
    "score_1 = nn1.evaluate(X_test_keras, y_test_keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras Tuners\n",
    "- Simplified approach:\n",
    "        - Using dropout to help prevent overfitting\n",
    "        - Alternate number of neurons in the hidden layer, activation functions\n",
    "\n",
    "- To search in a larger hyperparameter space: increase number of hidden layers, tune the dropout rate, optimizers, learning rate..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RandomSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a hypermodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner import HyperModel\n",
    "from kerastuner.tuners import RandomSearch\n",
    "class ClassifierHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "    \n",
    "    def build(self, HyperModel):     \n",
    "        model = Sequential()\n",
    "        model.add(\n",
    "            Dense(units=HyperModel.Int('units', min_value=24, max_value=44, step=4, default=40),\n",
    "                  activation=HyperModel.Choice(name = 'dense_activation',\n",
    "                                       values = ['relu', 'tanh', 'sigmoid'],\n",
    "                                       default='relu', ordered = False),\n",
    "                  input_shape=input_shape)\n",
    "            )\n",
    "        \n",
    "        model.add(\n",
    "            Dropout(HyperModel.Float(name='dropout', min_value=0.2, max_value=0.6, step=0.1, default=0.5))\n",
    "            )\n",
    "        \n",
    "        model.add(Dense(nb_classes))\n",
    "        model.add(Activation('softmax'))\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='categorical_crossentropy',metrics=['accuracy']\n",
    "            )\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (max_words,)\n",
    "hypermodel = ClassifierHyperModel(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuner's settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project ./untitled_project/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from ./untitled_project/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner_rs = RandomSearch(\n",
    "            hypermodel,\n",
    "            objective='val_accuracy',\n",
    "            seed=42,\n",
    "            max_trials=10,\n",
    "            executions_per_trial=2)\n",
    "\n",
    "es_callback = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_rs.search(X_train_keras, y_train_keras,\n",
    "                epochs=50,\n",
    "                validation_split=0.1,\n",
    "                batch_size=8,\n",
    "                callbacks=[es_callback],\n",
    "                verbose=1,\n",
    "                seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ./untitled_project\n",
      "Showing 5 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 32\n",
      "dense_activation: tanh\n",
      "dropout: 0.4000000000000001\n",
      "Score: 0.693233072757721\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 36\n",
      "dense_activation: relu\n",
      "dropout: 0.30000000000000004\n",
      "Score: 0.6902255713939667\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 28\n",
      "dense_activation: tanh\n",
      "dropout: 0.4000000000000001\n",
      "Score: 0.6887218058109283\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 32\n",
      "dense_activation: tanh\n",
      "dropout: 0.6000000000000001\n",
      "Score: 0.68721804022789\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 36\n",
      "dense_activation: relu\n",
      "dropout: 0.4000000000000001\n",
      "Score: 0.6857143044471741\n"
     ]
    }
   ],
   "source": [
    "tuner_rs.results_summary(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get best model by RandomSearch & check accuracy score on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 2s 12ms/step - loss: 1.6383 - accuracy: 0.6277\n"
     ]
    }
   ],
   "source": [
    "best_model_rs = tuner_rs.get_best_models(num_models=1)[0]\n",
    "loss, mse = best_model_rs.evaluate(X_test_keras, y_test_keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the hyperparameters found by RandomSearch, we'll train the model again, this time using smaller batch size, higher number of epochs while still keep the callbacks function to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2989/2989 [==============================] - 17s 5ms/step - loss: 5.4689 - accuracy: 0.1507 - val_loss: 3.9435 - val_accuracy: 0.3579\n",
      "Epoch 2/30\n",
      "2989/2989 [==============================] - 13s 4ms/step - loss: 3.3171 - accuracy: 0.4288 - val_loss: 3.1019 - val_accuracy: 0.4602\n",
      "Epoch 3/30\n",
      "2989/2989 [==============================] - 11s 4ms/step - loss: 2.4345 - accuracy: 0.5579 - val_loss: 2.5934 - val_accuracy: 0.5398\n",
      "Epoch 4/30\n",
      "2989/2989 [==============================] - 12s 4ms/step - loss: 1.8116 - accuracy: 0.6643 - val_loss: 2.2466 - val_accuracy: 0.5970\n",
      "Epoch 5/30\n",
      "2989/2989 [==============================] - 11s 4ms/step - loss: 1.4450 - accuracy: 0.7405 - val_loss: 1.9856 - val_accuracy: 0.6180\n",
      "Epoch 6/30\n",
      "2989/2989 [==============================] - 11s 4ms/step - loss: 1.1173 - accuracy: 0.8097 - val_loss: 1.8164 - val_accuracy: 0.6571\n",
      "Epoch 7/30\n",
      "2989/2989 [==============================] - 10s 3ms/step - loss: 0.8946 - accuracy: 0.8517 - val_loss: 1.6711 - val_accuracy: 0.6647\n",
      "Epoch 8/30\n",
      "2989/2989 [==============================] - 12s 4ms/step - loss: 0.6945 - accuracy: 0.8987 - val_loss: 1.5691 - val_accuracy: 0.6752\n",
      "Epoch 9/30\n",
      "2989/2989 [==============================] - 11s 4ms/step - loss: 0.5743 - accuracy: 0.9162 - val_loss: 1.4995 - val_accuracy: 0.6827\n",
      "Epoch 10/30\n",
      "2989/2989 [==============================] - 11s 4ms/step - loss: 0.4723 - accuracy: 0.9365 - val_loss: 1.4468 - val_accuracy: 0.6842\n",
      "Epoch 11/30\n",
      "2989/2989 [==============================] - 9s 3ms/step - loss: 0.4018 - accuracy: 0.9552 - val_loss: 1.4420 - val_accuracy: 0.6707\n",
      "Epoch 12/30\n",
      "2989/2989 [==============================] - 10s 3ms/step - loss: 0.3355 - accuracy: 0.9581 - val_loss: 1.3935 - val_accuracy: 0.6827\n",
      "Epoch 13/30\n",
      "2989/2989 [==============================] - 9s 3ms/step - loss: 0.2957 - accuracy: 0.9658 - val_loss: 1.3881 - val_accuracy: 0.6752\n",
      "Epoch 14/30\n",
      "2989/2989 [==============================] - 11s 4ms/step - loss: 0.2712 - accuracy: 0.9715 - val_loss: 1.3829 - val_accuracy: 0.6917\n",
      "Epoch 15/30\n",
      "2989/2989 [==============================] - 9s 3ms/step - loss: 0.2446 - accuracy: 0.9732 - val_loss: 1.3695 - val_accuracy: 0.6857\n",
      "Epoch 16/30\n",
      "2989/2989 [==============================] - 10s 3ms/step - loss: 0.2274 - accuracy: 0.9728 - val_loss: 1.3816 - val_accuracy: 0.6917\n",
      "Epoch 17/30\n",
      "2989/2989 [==============================] - 10s 3ms/step - loss: 0.1922 - accuracy: 0.9778 - val_loss: 1.3888 - val_accuracy: 0.6887\n",
      "Epoch 18/30\n",
      "2989/2989 [==============================] - 11s 4ms/step - loss: 0.1981 - accuracy: 0.9767 - val_loss: 1.3688 - val_accuracy: 0.6917\n",
      "Epoch 19/30\n",
      "2989/2989 [==============================] - 10s 3ms/step - loss: 0.1642 - accuracy: 0.9827 - val_loss: 1.3898 - val_accuracy: 0.6887\n",
      "Epoch 20/30\n",
      "2989/2989 [==============================] - 10s 3ms/step - loss: 0.1581 - accuracy: 0.9853 - val_loss: 1.4228 - val_accuracy: 0.6857\n",
      "Epoch 21/30\n",
      "2989/2989 [==============================] - 10s 3ms/step - loss: 0.1412 - accuracy: 0.9853 - val_loss: 1.4219 - val_accuracy: 0.6977\n",
      "Epoch 22/30\n",
      "2989/2989 [==============================] - 10s 3ms/step - loss: 0.1364 - accuracy: 0.9868 - val_loss: 1.4359 - val_accuracy: 0.6932\n",
      "Epoch 23/30\n",
      "2989/2989 [==============================] - 10s 3ms/step - loss: 0.1286 - accuracy: 0.9864 - val_loss: 1.4207 - val_accuracy: 0.6842\n"
     ]
    }
   ],
   "source": [
    "nn_rs = Sequential()\n",
    "nn_rs.add(Dense(32, input_shape=(max_words,)))\n",
    "nn_rs.add(Activation('tanh'))\n",
    "nn_rs.add(Dropout(0.4))\n",
    "\n",
    "nn_rs.add(Dense(nb_classes))\n",
    "nn_rs.add(Activation('softmax'))\n",
    "\n",
    "nn_rs.compile(loss='categorical_crossentropy',\n",
    "          optimizer='adam',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "es_callback = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    "    )\n",
    "\n",
    "history_rs = nn_rs.fit(X_train_keras, y_train_keras, epochs=30, validation_split=0.1,\n",
    "                      callbacks=[es_callback], batch_size=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 5ms/step - loss: 1.3983 - accuracy: 0.7005\n"
     ]
    }
   ],
   "source": [
    "loss, mse = nn_rs.evaluate(X_test_keras, y_test_keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperband Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners.hyperband import Hyperband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90 Complete [00h 02m 50s]\n",
      "val_accuracy: 0.6586466133594513\n",
      "\n",
      "Best val_accuracy So Far: 0.7248120307922363\n",
      "Total elapsed time: 01h 08m 27s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# tuner settings\n",
    "tuner_hb = Hyperband(hypermodel,\n",
    "                     max_epochs=35,\n",
    "                     objective='val_accuracy',\n",
    "                     factor=3,\n",
    "                     seed=42,\n",
    "                     executions_per_trial=2,\n",
    "                     directory='hyperband_tuner')\n",
    "\n",
    "hb_callback = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    "    )\n",
    "\n",
    "# launch tuning process\n",
    "tuner_hb.search(X_train_keras, y_train_keras,\n",
    "                epochs=35,\n",
    "                validation_split=0.1,\n",
    "                callbacks=[hb_callback],\n",
    "                batch_size=8,\n",
    "                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in hyperband_tuner/untitled_project\n",
      "Showing 3 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 40\n",
      "dense_activation: tanh\n",
      "dropout: 0.2\n",
      "tuner/epochs: 35\n",
      "tuner/initial_epoch: 12\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 771b6571cd69176a07a8019fa3a704f7\n",
      "Score: 0.7248120307922363\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 40\n",
      "dense_activation: tanh\n",
      "dropout: 0.30000000000000004\n",
      "tuner/epochs: 35\n",
      "tuner/initial_epoch: 12\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 88006f1a3993802fcbefa53be4c01578\n",
      "Score: 0.7210526466369629\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 40\n",
      "dense_activation: tanh\n",
      "dropout: 0.6000000000000001\n",
      "tuner/epochs: 35\n",
      "tuner/initial_epoch: 12\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: e46360c9fc380a9014ad2d39183bc472\n",
      "Score: 0.7180451154708862\n"
     ]
    }
   ],
   "source": [
    "tuner_hb.results_summary(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'units': 40, 'dense_activation': 'tanh', 'dropout': 0.2, 'tuner/epochs': 35, 'tuner/initial_epoch': 12, 'tuner/bracket': 3, 'tuner/round': 3, 'tuner/trial_id': '771b6571cd69176a07a8019fa3a704f7'}\n"
     ]
    }
   ],
   "source": [
    "best_hyperparameters_hb = tuner_hb.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hyperparameters_hb.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step - loss: 1.3165 - accuracy: 0.6830\n"
     ]
    }
   ],
   "source": [
    "best_model_hb = tuner_hb.get_best_models(num_models=1)[0]\n",
    "loss_hb, mse_hb = best_model_hb.evaluate(X_test_keras, y_test_keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the hyperparameters found by Hyperband, we'll train the model again, this time using smaller batch size, higher number of epochs while still keep the callbacks function to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2989/2989 [==============================] - 14s 4ms/step - loss: 5.2501 - accuracy: 0.1960 - val_loss: 3.4356 - val_accuracy: 0.4180\n",
      "Epoch 2/50\n",
      "2989/2989 [==============================] - 11s 4ms/step - loss: 2.5753 - accuracy: 0.5530 - val_loss: 2.4646 - val_accuracy: 0.5549\n",
      "Epoch 3/50\n",
      "2989/2989 [==============================] - 13s 4ms/step - loss: 1.5181 - accuracy: 0.7419 - val_loss: 1.9611 - val_accuracy: 0.6150\n",
      "Epoch 4/50\n",
      "2989/2989 [==============================] - 12s 4ms/step - loss: 0.9084 - accuracy: 0.8579 - val_loss: 1.6442 - val_accuracy: 0.6632\n",
      "Epoch 5/50\n",
      "2989/2989 [==============================] - 11s 4ms/step - loss: 0.5351 - accuracy: 0.9342 - val_loss: 1.4695 - val_accuracy: 0.6857\n",
      "Epoch 6/50\n",
      "2989/2989 [==============================] - 11s 4ms/step - loss: 0.3034 - accuracy: 0.9693 - val_loss: 1.3787 - val_accuracy: 0.6902\n",
      "Epoch 7/50\n",
      "2989/2989 [==============================] - 11s 4ms/step - loss: 0.1903 - accuracy: 0.9772 - val_loss: 1.3456 - val_accuracy: 0.6962\n",
      "Epoch 8/50\n",
      "2989/2989 [==============================] - 11s 4ms/step - loss: 0.1143 - accuracy: 0.9900 - val_loss: 1.3150 - val_accuracy: 0.6932\n",
      "Epoch 9/50\n",
      "2989/2989 [==============================] - 12s 4ms/step - loss: 0.0748 - accuracy: 0.9929 - val_loss: 1.3229 - val_accuracy: 0.6902\n",
      "Epoch 10/50\n",
      "2989/2989 [==============================] - 12s 4ms/step - loss: 0.0523 - accuracy: 0.9928 - val_loss: 1.3387 - val_accuracy: 0.6947\n",
      "Epoch 11/50\n",
      "2989/2989 [==============================] - 11s 4ms/step - loss: 0.0341 - accuracy: 0.9955 - val_loss: 1.3670 - val_accuracy: 0.6932\n",
      "Epoch 12/50\n",
      "2989/2989 [==============================] - 12s 4ms/step - loss: 0.0284 - accuracy: 0.9956 - val_loss: 1.4034 - val_accuracy: 0.6887\n",
      "Epoch 13/50\n",
      "2989/2989 [==============================] - 12s 4ms/step - loss: 0.0204 - accuracy: 0.9957 - val_loss: 1.4151 - val_accuracy: 0.6797\n"
     ]
    }
   ],
   "source": [
    "nn_hb = Sequential()\n",
    "nn_hb.add(Dense(40, input_shape=(max_words,)))\n",
    "nn_hb.add(Activation('tanh'))\n",
    "nn_hb.add(Dropout(0.2))\n",
    "\n",
    "nn_hb.add(Dense(nb_classes))\n",
    "nn_hb.add(Activation('softmax'))\n",
    "\n",
    "nn_hb.compile(loss='categorical_crossentropy',\n",
    "          optimizer='adam',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "\n",
    "hb_callback = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5\n",
    "    )\n",
    "\n",
    "history_hb = nn_hb.fit(X_train_keras, y_train_keras, epochs=50,\n",
    "                       callbacks=[hb_callback],\n",
    "                       validation_split=0.1, batch_size=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 9ms/step - loss: 1.4185 - accuracy: 0.7222\n"
     ]
    }
   ],
   "source": [
    "loss_best_hb, accuracy_best_hb = nn_hb.evaluate(X_test_keras, y_test_keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make final predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_nn = np.argmax(nn_hb.predict(new_data), axis=-1)\n",
    "\n",
    "# # reverse the encoding to the initial labels\n",
    "# y_pred_nn = encoder.inverse_transform(predictions_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, for this data set, SGD performs better than 1 hidden layer MLP. However, with larger training set, more complex models like MLP may detect patterns better.\n",
    "\n",
    "Further improvement on MLP can be explored by increasing number of hidden layers and searching within a larger hyperparameter space."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "214px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
